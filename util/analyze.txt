ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
module.conv1.weight : torch.Size([64, 3, 3, 3])
module.bn1.weight : torch.Size([64])
module.bn1.bias : torch.Size([64])
module.layer1.0.conv1.weight : torch.Size([64, 64, 3, 3])
module.layer1.0.bn1.weight : torch.Size([64])
module.layer1.0.bn1.bias : torch.Size([64])
module.layer1.0.conv2.weight : torch.Size([64, 64, 3, 3])
module.layer1.0.bn2.weight : torch.Size([64])
module.layer1.0.bn2.bias : torch.Size([64])
module.layer1.1.conv1.weight : torch.Size([64, 64, 3, 3])
module.layer1.1.bn1.weight : torch.Size([64])
module.layer1.1.bn1.bias : torch.Size([64])
module.layer1.1.conv2.weight : torch.Size([64, 64, 3, 3])
module.layer1.1.bn2.weight : torch.Size([64])
module.layer1.1.bn2.bias : torch.Size([64])
module.layer2.0.conv1.weight : torch.Size([128, 64, 3, 3])
module.layer2.0.bn1.weight : torch.Size([128])
module.layer2.0.bn1.bias : torch.Size([128])
module.layer2.0.conv2.weight : torch.Size([128, 128, 3, 3])
module.layer2.0.bn2.weight : torch.Size([128])
module.layer2.0.bn2.bias : torch.Size([128])
module.layer2.0.shortcut.0.weight : torch.Size([128, 64, 1, 1])
module.layer2.0.shortcut.1.weight : torch.Size([128])
module.layer2.0.shortcut.1.bias : torch.Size([128])
module.layer2.1.conv1.weight : torch.Size([128, 128, 3, 3])
module.layer2.1.bn1.weight : torch.Size([128])
module.layer2.1.bn1.bias : torch.Size([128])
module.layer2.1.conv2.weight : torch.Size([128, 128, 3, 3])
module.layer2.1.bn2.weight : torch.Size([128])
module.layer2.1.bn2.bias : torch.Size([128])
module.layer3.0.conv1.weight : torch.Size([256, 128, 3, 3])
module.layer3.0.bn1.weight : torch.Size([256])
module.layer3.0.bn1.bias : torch.Size([256])
module.layer3.0.conv2.weight : torch.Size([256, 256, 3, 3])
module.layer3.0.bn2.weight : torch.Size([256])
module.layer3.0.bn2.bias : torch.Size([256])
module.layer3.0.shortcut.0.weight : torch.Size([256, 128, 1, 1])
module.layer3.0.shortcut.1.weight : torch.Size([256])
module.layer3.0.shortcut.1.bias : torch.Size([256])
module.layer3.1.conv1.weight : torch.Size([256, 256, 3, 3])
module.layer3.1.bn1.weight : torch.Size([256])
module.layer3.1.bn1.bias : torch.Size([256])
module.layer3.1.conv2.weight : torch.Size([256, 256, 3, 3])
module.layer3.1.bn2.weight : torch.Size([256])
module.layer3.1.bn2.bias : torch.Size([256])
module.layer4.0.conv1.weight : torch.Size([512, 256, 3, 3])
module.layer4.0.bn1.weight : torch.Size([512])
module.layer4.0.bn1.bias : torch.Size([512])
module.layer4.0.conv2.weight : torch.Size([512, 512, 3, 3])
module.layer4.0.bn2.weight : torch.Size([512])
module.layer4.0.bn2.bias : torch.Size([512])
module.layer4.0.shortcut.0.weight : torch.Size([512, 256, 1, 1])
module.layer4.0.shortcut.1.weight : torch.Size([512])
module.layer4.0.shortcut.1.bias : torch.Size([512])
module.layer4.1.conv1.weight : torch.Size([512, 512, 3, 3])
module.layer4.1.bn1.weight : torch.Size([512])
module.layer4.1.bn1.bias : torch.Size([512])
module.layer4.1.conv2.weight : torch.Size([512, 512, 3, 3])
module.layer4.1.bn2.weight : torch.Size([512])
module.layer4.1.bn2.bias : torch.Size([512])
module.linear.weight : torch.Size([10, 512])
module.linear.bias : torch.Size([10])
module.conv1.weight : tensor(53.1042)
module.bn1.weight : tensor(4.7372)
module.bn1.bias : tensor(4.4211)
module.layer1.0.conv1.weight : tensor(213.8517)
module.layer1.0.bn1.weight : tensor(3.2245)
module.layer1.0.bn1.bias : tensor(3.7916)
module.layer1.0.conv2.weight : tensor(317.6191)
module.layer1.0.bn2.weight : tensor(3.8233)
module.layer1.0.bn2.bias : tensor(4.0191)
module.layer1.1.conv1.weight : tensor(368.8593)
module.layer1.1.bn1.weight : tensor(2.5854)
module.layer1.1.bn1.bias : tensor(2.9341)
module.layer1.1.conv2.weight : tensor(351.2344)
module.layer1.1.bn2.weight : tensor(4.5412)
module.layer1.1.bn2.bias : tensor(3.4997)
module.layer2.0.conv1.weight : tensor(767.2125)
module.layer2.0.bn1.weight : tensor(2.3142)
module.layer2.0.bn1.bias : tensor(4.7369)
module.layer2.0.conv2.weight : tensor(1429.6543)
module.layer2.0.bn2.weight : tensor(4.4756)
module.layer2.0.bn2.bias : tensor(3.9438)
module.layer2.0.shortcut.0.weight : tensor(118.4986)
module.layer2.0.shortcut.1.weight : tensor(4.8809)
module.layer2.0.shortcut.1.bias : tensor(3.9438)
module.layer2.1.conv1.weight : tensor(1204.1478)
module.layer2.1.bn1.weight : tensor(3.1612)
module.layer2.1.bn1.bias : tensor(3.8400)
module.layer2.1.conv2.weight : tensor(1085.9514)
module.layer2.1.bn2.weight : tensor(6.1253)
module.layer2.1.bn2.bias : tensor(6.0177)
module.layer3.0.conv1.weight : tensor(2606.3931)
module.layer3.0.bn1.weight : tensor(3.0778)
module.layer3.0.bn1.bias : tensor(5.8763)
module.layer3.0.conv2.weight : tensor(5017.7368)
module.layer3.0.bn2.weight : tensor(5.4838)
module.layer3.0.bn2.bias : tensor(5.8372)
module.layer3.0.shortcut.0.weight : tensor(337.9850)
module.layer3.0.shortcut.1.weight : tensor(5.4678)
module.layer3.0.shortcut.1.bias : tensor(5.8372)
module.layer3.1.conv1.weight : tensor(4777.3711)
module.layer3.1.bn1.weight : tensor(4.1545)
module.layer3.1.bn1.bias : tensor(6.5416)
module.layer3.1.conv2.weight : tensor(3393.4897)
module.layer3.1.bn2.weight : tensor(11.5805)
module.layer3.1.bn2.bias : tensor(10.3275)
module.layer4.0.conv1.weight : tensor(5300.3716)
module.layer4.0.bn1.weight : tensor(11.0080)
module.layer4.0.bn1.bias : tensor(13.3460)
module.layer4.0.conv2.weight : tensor(6378.3882)
module.layer4.0.bn2.weight : tensor(15.5078)
module.layer4.0.bn2.bias : tensor(12.3320)
module.layer4.0.shortcut.0.weight : tensor(658.1115)
module.layer4.0.shortcut.1.weight : tensor(4.6441)
module.layer4.0.shortcut.1.bias : tensor(12.3320)
module.layer4.1.conv1.weight : tensor(4384.6558)
module.layer4.1.bn1.weight : tensor(12.3634)
module.layer4.1.bn1.bias : tensor(10.8855)
module.layer4.1.conv2.weight : tensor(2447.5818)
module.layer4.1.bn2.weight : tensor(19.6875)
module.layer4.1.bn2.bias : tensor(8.6948)
module.linear.weight : tensor(135.8134)
module.linear.bias : tensor(0.0558)
